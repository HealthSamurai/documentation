apiVersion: batch/v1
kind: CronJob
metadata:
  name: meilisearch-reindex-fhirbase
  namespace: gitbok
spec:
  schedule: "30 * * * *"  # Every hour at 30 minutes (offset from docs)
  concurrencyPolicy: Forbid  # Don't start new job if previous is still running
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 2
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: docs-scraper
            image: getmeili/docs-scraper:latest
            env:
            - name: MEILISEARCH_HOST_URL
              value: "http://meilisearch.gitbok.svc.cluster.local:7700"
            - name: MEILISEARCH_API_KEY
              valueFrom:
                secretKeyRef:
                  name: meilisearch-secret
                  key: master-key
            - name: INDEX_NAME
              value: "fhirbase"
            volumeMounts:
            - name: config
              mountPath: /docs-scraper/config.json
              subPath: config.json
            command: ["/bin/sh", "-c"]
            args:
            - |
              set -e
              echo "Starting reindexing for index: $INDEX_NAME"

              # 1. Run scraper to populate temp index
              echo "Running docs-scraper to populate ${INDEX_NAME}_temp..."
              pipenv run ./docs_scraper config.json

              # 2-5. Handle index swapping with Python (since curl is not available)
              python3 -c "
              import os
              import time
              import json
              import urllib.request
              import urllib.error

              INDEX_NAME = os.environ.get('INDEX_NAME')
              MEILISEARCH_HOST_URL = os.environ.get('MEILISEARCH_HOST_URL')
              MEILISEARCH_API_KEY = os.environ.get('MEILISEARCH_API_KEY')

              headers = {
                  'Authorization': f'Bearer {MEILISEARCH_API_KEY}',
                  'Content-Type': 'application/json'
              }

              def make_request(url, method='GET', data=None):
                  req = urllib.request.Request(url, headers=headers, method=method)
                  if data:
                      req.data = json.dumps(data).encode('utf-8')
                  try:
                      with urllib.request.urlopen(req) as response:
                          return response.getcode(), response.read().decode('utf-8')
                  except urllib.error.HTTPError as e:
                      return e.code, e.read().decode('utf-8')

              # Check if indexes exist
              main_code, _ = make_request(f'{MEILISEARCH_HOST_URL}/indexes/{INDEX_NAME}')
              temp_code, _ = make_request(f'{MEILISEARCH_HOST_URL}/indexes/{INDEX_NAME}_temp')

              print(f'Index status: {INDEX_NAME}={main_code}, {INDEX_NAME}_temp={temp_code}')

              # Create empty main index if it doesn't exist
              if main_code != 200:
                  print(f'Creating empty index: {INDEX_NAME}')
                  code, resp = make_request(
                      f'{MEILISEARCH_HOST_URL}/indexes',
                      'POST',
                      {'uid': INDEX_NAME, 'primaryKey': 'objectID'}
                  )
                  time.sleep(2)

              # Swap indexes if temp exists
              if temp_code == 200:
                  print(f'Swapping indexes: {INDEX_NAME} <-> {INDEX_NAME}_temp')
                  swap_code, swap_resp = make_request(
                      f'{MEILISEARCH_HOST_URL}/swap-indexes',
                      'POST',
                      [{'indexes': [INDEX_NAME, f'{INDEX_NAME}_temp']}]
                  )

                  if swap_code not in [200, 202]:
                      print(f'Error: Swap failed with code {swap_code}')
                      print(f'Response: {swap_resp}')
                      exit(1)

                  time.sleep(2)

                  # Delete old temp index
                  print(f'Deleting old temp index: {INDEX_NAME}_temp')
                  make_request(f'{MEILISEARCH_HOST_URL}/indexes/{INDEX_NAME}_temp', 'DELETE')

                  print(f'Reindexing completed successfully for {INDEX_NAME}')
              else:
                  print(f'Error: Temp index {INDEX_NAME}_temp was not created')
                  exit(1)
              "
          volumes:
          - name: config
            configMap:
              name: meilisearch-scraper-config-fhirbase